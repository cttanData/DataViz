---
title: "Assignment - VAST Challenge 2021"
description: |
  [VAST Challenge 2021](https://vast-challenge.github.io/2021/). Applying visual analytics to gain Insight.....  
author:
  - name: Choo T Tan
    url: {}
date: 06-28-2021
output:
  distill::distill_article:
    toc: true
    toc_depth: 2
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, error = FALSE, fig.retina = 3)
```

```{r echo = FALSE, warning = FALSE}
packages <- c('sf','tidyverse', 'igraph', 'plotly', 'ggiraph','lubridate', 'clock', 'ggraph', 'DT', 'tmap','visNetwork','tidygraph',"timevis")
for (p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p,character.only = T)
}
rm(p)
```

# 1.0 Introduction 
The assignment is based on [VAST Challenge 2021](https://vast-challenge.github.io/2021/) where it has selected solve the [Mini Challenges 2 (MC2)](https://vast-challenge.github.io/2021/MC2.html) out of the 3 mini challenges via visual analytics out. The fictitious scenario was based on a Tethys-based natural gas production company GAStech in the country of Kronos where it has made remarkable profits and strong relationship with the government. However, GAStech has not been as successful in demonstrating environmental stewardship. Several employee went missing in January 2014 after a successful initial public offering. It was suspected that the disappearance might be associated with an organization known as the Protectors of Kronos (POK). However, things may not be so simplicity. Thus, one has been tasked to assist the law enforcement from Kronos and Tethys in solving the assigned task via visual analytics. 

# 2.0 Requirements 
The main task is to identify suspicious patterns of behavior from the transaction done by GASTech employees. You must cope with uncertainties that result from missing, conflicting, and imperfect data to make recommendations for further investigation. There are 4 main CSV files with 15 Korons geospatial data in tif or shp etc. [here](https://vast-challenge.github.io/2021/MC2.html) The data is based on last 14 days, 6 - 19 January 2014 prior to the disappearance. __As part of assignment constraint, only libraries from R programming languages can be used to complete the analytics.__ The CSV files are namely (1) credit card transaction, (2) loyalty card transaction, (3) geospatial tracking data for company cars which not know to employee, (4) car assignment. The relevant questions to be answered are: 

1. Using just the credit and loyalty card data, identify the most popular locations, and when they are popular. What anomalies do you see? What corrections would you recommend to correct these anomalies? Please limit your answer to 8 images and 300 words.

2. Add the vehicle data to your analysis of the credit and loyalty card data. How does your assessment of the anomalies in question 1 change based on this new data? What discrepancies between vehicle, credit, and loyalty card data do you find? Please limit your answer to 8 images and 500 words.

3. Can you infer the owners of each credit card and loyalty card? What is your evidence? Where are there uncertainties in your method? Where are there uncertainties in the data? Please limit your answer to 8 images and 500 words.

4. Given the data sources provided, identify potential informal or unofficial relationships among GASTech personnel. Provide evidence for these relationships. Please limit your response to 8 images and 500 words.

5. Do you see evidence of suspicious activity? Identify 1- 10 locations where you believe the suspicious activity is occurring, and why Please limit your response to 10 images and 500 words.

# 3.0 Liteature Review and Approach


The investigation will be done in 3 main steps:

1. **Data Preparation**. Require data cleaning and transformation to aid the data exploratory. Main focus in to establish the required data point to link up the 3 main files associated with geospatial tracking, credit and loyalty cards transactions. 

2. **Exploratory Data Analysis (EDA)**.  Explain the various R library that would use to build visualisation tool to aid the EDA to discover the required insights for the questions.

3. **Exploration Sharing**. Story telling on the discerned insights.

# 4.0 Date Preparation.
## 4.1 Credit and Loyalty Cards.
For credit and loyalty cards csv files, its contained transaction timestamp, location, price and card number. The timestamp within the files was in different formation eg %m/%d/%Y vs %m/%d/%y etc and credit card came with transacted date and time as compared loyalty only have date. Perform required data wrangling based on observation to resolve the datetime format (i.e. using lubridate and clock) and set card numbers as character. In addition, create date (i.e. Date, rename timestamp in loyalty card to date), weekday and hour for subsequent EDA. Code chuck and glimpse of prepared credit card dataset:

```{r, clean up credit, echo= TRUE}
credit <- read_csv("data/aspatial/cc_data.csv")

#cleaning up on datetime format, since there is %y vs %Y. Try to use ifelse but syntac error that cant be resolved
credit <- credit %>% # separate them into fine entity
  separate(timestamp, into = c("date","time"), sep=" ",remove = TRUE) %>%
  separate(time, into = c("hr", "min"), sep=":",remove = TRUE) %>%
  separate(date, into = c("mth", "day", "yr"), sep="/",remove = TRUE) %>%
  mutate(yr=2014)

pack <- c('yr','mth','day','hr','min') # convert to numeric since make_datetime need numeric format
for (p in pack){
  credit <- credit %>% mutate_at(c(p),as.numeric)
}

credit  <- credit %>% 
  mutate(timestamp = make_datetime(yr,mth,day,hr,min)) %>%
  mutate(date = make_date(yr,mth,day)) %>%
  dplyr::select(-yr,-mth,-min) %>%
  relocate(timestamp, date, .before=day) %>%
  arrange(last4ccnum, timestamp)

credit$wkday <- lubridate::wday(credit$timestamp, label= TRUE, abbr = FALSE)
credit$last4ccnum = as.character(credit$last4ccnum) # convert it to character
rm(p,pack)
glimpse(credit)
```

A much more simplify code of the above mentioned was used to prepare the loyalty card data set. 

```{r, clean up loyalty card, echo=TRUE}

loyalty <- read_csv("data/aspatial/loyalty_data.csv")

loyalty<-loyalty %>% 
  separate(timestamp, into = c("mth", "day", "yr"), sep="/",remove = TRUE) %>%
  mutate(yr=2014)

pack <- c('yr','mth','day') # convert to numeric since make_datetime need numeric format
for (p in pack){
  loyalty  <- loyalty %>% mutate_at(c(p),as.numeric)
}

loyalty  <- loyalty %>% 
  mutate(date = make_date(yr,mth,day)) %>%
  dplyr::select(-yr,-mth) %>%
  arrange(loyaltynum)
rm(p,pack)
```
 
## 4.2 Geospatial Tracking. 
As previous, necessary conversion of Timestamp and id variables to the proper data type. To ease the mapping of location to geospatial values, decided to round off its value to four decimal places. The main focus was to determine the trip within the geospatial tracking dataset for respective vehicle ID. Trip was defined as a continues traveling from point A to B with time lag less than 300secs. 300 secs was arbitrary decided based on screening through the data set. With the trip formed, one could determine the traveling locations for respective veh ID overtimes.  

Code chuck for determine the trip within the days for respective vehicle ID.

```{r, Determine Veh Trip, eval=FALSE, echo=TRUE}
gps <- read_csv("data/aspatial/gps.csv")

#covert to appropriate datetype for timestamp
gps$Timestamp <- date_time_parse(gps$Timestamp,zone ="", format = "%m/%d/%Y %H:%M:%S")
gps$id <- as.character(gps$id)

gps <- gps %>% #compute time difference & rd off GPS 
  arrange(id, Timestamp) %>%
  mutate(diff = (Timestamp - lag(Timestamp, default = first(Timestamp)))) %>%
  mutate(rlat = round(lat, digits = 4), rlong = round(long, digits=4))

# initialisation the veh ID
pack <- c( "1", "2","3","4","5","6","7","8","9","10", "11","12","13","14","15","16","17","18","19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "101", "104", "105", "106","107")

trip_lag = 300 # interval <= 5mins considered as a single trip

for (p in pack){
  temp <- gps %>% filter(id==p) %>%
    arrange(id, Timestamp) 
  count = 1
  
  for(i in 1:nrow(temp)){
    if(temp[i,'diff']<=trip_lag){
      temp[i,'trip']=count
    }else{
      count = count + 1
      temp[i,'trip'] = count
     }
  } 
  if(p==1){mgps <- temp
  }else{
    cgps = merge(mgps, temp, all.x=T, all.y=T)  
  }
}
cgps <-  cgps %>% arrange(id, Timestamp) #clean GPS data
write.csv(cgps, "data/aspatial/fulltrip_gps.csv", row.names  = FALSE)
rm(temp, gps)
```

```{r, echo=FALSE}
cgps <- read_csv("data/aspatial/fulltrip_gps.csv")
cgps$id = as.character(cgps$id)
cgps$trip = as.character(cgps$trip)
```

Code chuck for conversion to sf dataframe for display in tmap.

```{r, echo=TRUE}
bgmap<- raster::raster("data/geospatial/MC2-tourist_modified.tif")

gps_sf <- st_as_sf(cgps, coords = c("long","lat"), crs = 4326) # should form geometric data first

gps_lines <- gps_sf %>% 
  group_by(id, trip) %>%
  summarize(m = mean(Timestamp), do_union=FALSE) %>%
  st_cast("MULTILINESTRING")
```

```{r, echo=FALSE, eval=FALSE}
gps_points <- gps_sf %>% 
  group_by(id,trip) %>%
  summarize(m = mean(Timestamp), do_union=FALSE) %>%
  st_cast("POINT")
```

Code chuck for plotting a trip for example Veh ID 3.

```{r, layout="l-body",fig.height = 6, fig.align='centre', warning = FALSE, echo=TRUE }

gps_lines_s <- gps_lines %>%
  filter(id==3, trip==6)

tmap_mode("plot")
tm_shape(bgmap) +
  tm_rgb(bgmap, r = 1,g = 2,b = 3,
       alpha = NA,
       saturation = 1,
       interpolate = TRUE,
       max.value = 255) +
  tm_shape(gps_lines_s) +
  tm_lines(col = "navy", lwd=2, alpah=0.7)

```
```{r, warning=FALSE, message= FALSE, eval=FALSE}
gps_points_s <- gps_points %>% 
   filter(id==5, trip==2)

tmap_mode("plot")
tm_shape(bgmap) +
  tm_rgb(bgmap, r =1,g = 2,b =3,
         alpha = NA,
         saturation = 1,
         interpolate = TRUE,
         max.value = 255) +
  tm_shape(gps_points_s) + 
  tm_facets(by="id",free.coords = FALSE) +
  tm_dots("navy", size = .05)
  tm_layout(panel.label.rot = c(0, 90), panel.label.size = 2)
```

# 5.0 Exploratory Data Analysis.
## 5.1 Establishing the Link between Credit and Loyalty Card Data Set.

```{r, echo=FALSE}
uniC<- length(unique(credit$last4ccnum))
uniL <- length(unique(loyalty$loyaltynum))
uniCL <- length(unique(credit$location))
uniLL <- length(unique(loyalty$location))
dCLL <- credit$location[!(credit$location %in% loyalty$location)]
dCLP <- credit$price[!(credit$location %in% loyalty$location)]
```

Reference to the company employee records in challenge 1, GASTech has 54 staffs. However, unique count on the credit and loyalty card numbers has shown `r uniC` and `r uniL` count respectively. Its alluded that one of the staff could have 2 credit cards. Moreover,a unique count on the number of transacted locations for each data set has shown that there were `r uniCL` and `r uniLL` locations for credit and loyalty card respectively. The additional location in credit card data set "`r dCLL`" with a transaction amount "`r dCLP`".

To merge both data sets, would determine the common set via inner join operations based on date, location and price. It observed that inner join has 1087 observations, while anti join has 409 and 311 disjoint for credit and loyalty card transaction respectively. The inner join has created 6 extra observations (1392 data points from loyalty - anti join 311 = 1081 or 1490 data points from credit - anti join 409 = 1081) due to observations having similar values defined for the inner join operation. The duplicated observations were identified and deleted. It also validated that the inner join contained the full set of credit and loyalty cards numbers and thus would be used to determine the unique pairing of credit to loyalty card. In addition, it also discerned that the inner join did not contain Kronos Mart and Daily Dealz as the transaction location. This implied that transactions at these two locations likely done by either of the card only.  

Code chuck for inner join and finding distinct pair.

```{r, inner join Credit and Loyalty to determine relationship}
ijoin <- credit %>%
  inner_join(loyalty,by=c('date','location','price','day')) %>%
  filter(!(last4ccnum == "4795" & loyaltynum == "L2070" )) %>%
  filter(!(last4ccnum == "8332" & loyaltynum == "L8566" )) %>%
  filter(!(last4ccnum == "5368" & loyaltynum == "L6119" )) %>%
  filter(!(last4ccnum == "7889" & loyaltynum == "L2247" )) %>%
  filter(!(last4ccnum == "5921" & loyaltynum == "L9406" )) %>%
  filter(!(last4ccnum == "4948" & loyaltynum == "L3295" ))   

ijoin <- ijoin %>% # compute of distinct pairing, X1-Y1, X1-Y2, X2Y3 etc  
  group_by(last4ccnum) %>%
  mutate(ndist = n_distinct(loyaltynum)) %>%
  ungroup() %>%
  group_by(loyaltynum) %>%
  mutate(ndist = if_else(ndist==1,n_distinct(last4ccnum), ndist)) %>%
  relocate(wkday, .before=location) %>%
  ungroup()

```

To determine the pairing, would need to determine the number of distinct count between a credit-loyalty pair based on a fixed credit card number. i.e. X1-Y1, X2-Y2 etc. Logically, there should only be one distinct pairing between both cards assuming a holder has each card.  However,it was discerned that some credit cards has more than a distinct pair. eg X1-Y1, X1-Y2 . This could be due to the fact that the credit card holder has more than one loyalty card or vice verse. To visualise the relationship, would use igraph to built a bipartite graph with nodes as credit and loyalty cards, edges as transaction. Edge weight was based on number of transactions for each distinct credit-loyalty pair. To minimise cluttering so to discover the credit card with more than a distinct pair, the data set would be filtered for distinct pairing count >=2 before group by via both cards. Inking was done on the igraph output, the code chuck and bipartite graph were shown below.

```{r message = FALSE, warning = FALSE}
#forming the bipartite graph
bigraph <- ijoin %>% # filter out unique pairing and count
  filter(ndist >= 2)%>%
  group_by(last4ccnum,loyaltynum) %>%
  summarise(weights=n()) %>%
  mutate_at(c("weights"), as.numeric)%>%
  arrange(loyaltynum) %>%
  ungroup()

#covert to igraph dataframe, inking and plot bipartite graph
bg<- graph.data.frame(bigraph, directed = TRUE)
V(bg)$type <- bipartite_mapping(bg)$type # assign vertex or nodes,

shape <- c("circle", "square")
E(bg)$color[E(bg)$weights<=5] <- 'red'
E(bg)$color[E(bg)$weights>5] <- 'sky blue'
```
```{r message = FALSE,layout="l-body",fig.height = 6, fig.align ="centre", fig.cap = "Bipartite Graph of Credit(Orange) and Loyalty(Pink) Cards.", warning = FALSE}
plot(bg, layout=layout.bipartite, 
     vertex.color=c("orange","pink")[V(bg)$type+1], vertex.size=20, vertex.label.cex=0.8,
     vertex.shape = shape[V(bg)$type+1],
     edge.width = E(bg)$weights*0.8,
     edge.label=E(bg)$weights, edge.label.cex=0.8, edge.label.color ="black", legend=TRUE)

mapping <- ijoin %>%
  count(last4ccnum,loyaltynum) %>%
  arrange(last4ccnum) %>%
  dplyr::select(-n) 
write.csv(mapping, "data/mapping_tmp.csv")
rm(mapping, bg, bigraph)
```

From the bipartite graph, L6267 was used by both credit cards 6691 and 6899. That could account for the short of one loyalty card as in Section 4. There should be some form of relationship between credit card 1286 and 9241 holders given the high usage of the latter loyalty card by the former. Nonetheless, 1283 will be tagged to L3572. Moving on, credit card would be used as the anchoring point for exploration where its pairing to loyalty card would be based on the established relationship here. The established pairing was saved in a csv file for future usage.  

```{r, forming the full file for credit and loyalty, warning= FALSE} 
# load the mapping of relationship generate the relationship link
mapping <- read_csv("data/aspatial/mapping.csv")
mapping$tmpC <- as.character(mapping$tmpC)
mapping$tmpL <- as.character(mapping$tmpL)
mapping$VehID <- as.character(mapping$VehID)
```

The full data set for both cards was created using full join on both data sets, removing the duplicate observations determined above. Then mapping of credit cards to the loyalty card was done in full data set.(inclusive of transaction via loyalty card only) In additional, create additional columns like cardtype (transaction with both cards or credit or loyalty card only) to support downstream visualisation. The code chuck and glimpse of the data set was given below. 

```{r,final credit-loyalty dataset } 
fjoin <- credit %>%
  full_join(loyalty,by=c('date','location','price','day')) %>%
  filter(!(last4ccnum == "4795" & loyaltynum == "L2070" & !is.na(last4ccnum) & !is.na(loyaltynum))) %>%
  filter(!(last4ccnum == "8332" & loyaltynum == "L8566" & !is.na(last4ccnum) & !is.na(loyaltynum))) %>%
  filter(!(last4ccnum == "5368" & loyaltynum == "L6119" & !is.na(last4ccnum) & !is.na(loyaltynum))) %>%
  filter(!(last4ccnum == "7889" & loyaltynum == "L2247" & !is.na(last4ccnum) & !is.na(loyaltynum))) %>%
  filter(!(last4ccnum == "5921" & loyaltynum == "L9406" & !is.na(last4ccnum) & !is.na(loyaltynum))) %>%
  filter(!(last4ccnum == "4948" & loyaltynum == "L3295" & !is.na(last4ccnum) & !is.na(loyaltynum)))   

tmp <- mapping %>% dplyr::select(-VehID,-Department)
fjoin <- fjoin %>% 
          arrange(last4ccnum, loyaltynum) %>%
          left_join(tmp, by= c("loyaltynum"="tmpL")) %>%
          mutate(ccard = ifelse(is.na(last4ccnum),tmpC, last4ccnum)) %>%
          mutate(cardtype = ifelse(is.na(loyaltynum),"credit",ifelse(is.na(last4ccnum),"loyalty","both"))) %>%
          dplyr::select(-tmpC) 

tmp <- mapping %>% dplyr::select(-tmpL)
fjoin <- fjoin %>% 
          arrange(ccard, timestamp) %>%
          left_join(tmp, by= c("ccard"="tmpC"))

fjoin$wkday <- lubridate::wday(fjoin$date, label= TRUE, abbr = FALSE)
fjoin$hr <- as.integer(fjoin$hr)
fjoin$day <- as.integer(fjoin$day)

write.csv(fjoin, "data/aspatial/credit_loy.csv", row.names  = FALSE)
rm(mapping,tmp)
glimpse(fjoin)
```

## 5.2  Establishing the Link between Geospatial Tracking and Merged Transaction Data Set.

The geospatial tracking data set has 35 and 5 unique private company car and truck respectively. Since there are 54 GASTech personnel, not everyone could be associated with geospatial tracking data. The only link point between the tracking and transactions data sets would be the GPS values for the transaction locations. The values were determined based on an exploration on discerned patterns that would help to grill down into the GPS values in the tracking data. One should progressively hunt for patterns at a smaller subsets such as locations or credit card with low transaction volume, vehicle ID with smaller number of trips, activities on weekends and then expand to larger data subset. Numerous visualisation aids would be used to assist in triangulate the location GPS values. The visaulisation aids as follows: 

1. __Plot via ggplot, ggirafe or ploty__. Example of a location with low transaction volume plot by ggplot with ggirafe. From here,one observed 2540 and 9683 visited the hotel twice a week during the weekdays and timestamp. i.e. Tue/Fri or Wed/Fri. 

```{r}
p <- fjoin %>% separate(timestamp, into = c("date","time"), sep=" ",remove = FALSE) %>%
  filter (location=="Chostus Hotel") %>% 
  ggplot(aes(x=day, fill=cardtype)) + 
  geom_bar_interactive(aes(tooltip = time), width=1) +
  scale_fill_manual(values=c("#1569C7", "orange","#2E8B57"))+
  scale_y_continuous(breaks=seq(0,2,1)) +
  scale_x_continuous(breaks=seq(6,19,1)) + 
  labs(title = expression(underline("Transaction at Chostus Hotel with Facet(Credit Card No) & Time Tooltip.")),
       y="No. of Transaction",
       x=" X Jan 2014",
       fill="Card Type") + 
  facet_grid(row = vars(ccard), scales="free_y", space="free_y")+  
  theme_classic()+ 
  theme(axis.text.x = element_text(size=6),
        axis.text.y = element_text(size=6),
        axis.title.x = element_text(size=8),
        axis.title.y = element_text(size=8),
        panel.grid.minor = element_blank(),
        legend.direction="vertical",
        legend.title = element_text(color = "blue", size = 8),
        legend.background = element_rect(fill = "light yellow"),
        legend.text=element_text(size=7),
        legend.key = element_rect(size = 0.5),
        legend.key.size = unit(0.8, 'lines'),
        plot.title = element_text(size=10,hjust = 0.5,face="bold")
        )
gg <- girafe(ggobj=p, width_svg = 6, height_svg=6*0.618)
gg <- girafe_options(gg, opts_tooltip(opacity = .9,
                                    offx = 20, offy = -10, use_fill = TRUE, use_stroke = TRUE,
                                    delay_mouseout = 1000) )
gg
```

2. __datatable__. Leveraging the datatable to zoom into potential vehicle ID where the timestamp was within 15mins of the transaction time. To streamline the data volume so that it was supportable by datetable, only the start point for respective trip would be used. The code chuck to determine the trip start point and datatable was appended below. 

```{r,layout="l-body"}
cgps$trip <- as.integer(cgps$trip) # formate to ease sorting
cgps$id <- as.integer(cgps$id) 

tmp <- cgps %>% group_by(id,trip) %>% # to find trip start point by group_by id and trip 
  summarise (count =n(),timestamp = first(Timestamp), lat = first(rlat), long= first(rlong)) %>%
  filter(count>1) %>% dplyr::select(-count) %>%
  arrange(id, trip)
```
```{r,layout="l-page"}
datatable(tmp, filter ='top',class = 'cell-border stripe',rownames=FALSE,
           options = list(autoWidth = TRUE, columnDefs = list(list(className = 'dt-center', targets = "_all"))),
           colnames = c("Vehicle ID","Trip ID", "Timestamp","Lat", "Long ")) %>%
  formatStyle(0, target ='row',color = 'Black', backgroundColor = 'light green', lineHeight ='70%')

```
3. __tmap__. With the information obtained above, explore the likely vehicle id tracking data via visual matching via tmap plotting and filtering for vehicle id and trip information in tmap. (same source code as in Section 3) 

Plot of Vehicle ID 33 with Trip 16:

```{r, echo=FALSE, layout="l-body",fig.height = 6, fig.align='centre', warning = FALSE }
gps_lines_s <- gps_lines %>%
  filter( id==33, trip==16)

tmap_mode("plot")
tm_shape(bgmap) +
  tm_rgb(bgmap, r = 1,g = 2,b = 3,
       alpha = NA,
       saturation = 1,
       interpolate = TRUE,
       max.value = 255) +
  tm_shape(gps_lines_s) +
  tm_lines(col = "navy", lwd=2, alpah=0.7)

```
Progressively exploring from small to larger data subset while compiling the GPS values for the interested locations and tagged it to the geographical tracking data. For company truck, one could focus transaction at industries locations such as Abila Airport, Kronos Pipe and irrigation, Carlyle Chemical Inc, Maximum iron and Steel etc and built up from there.  With the naming tagged, the geospatial tracking data set would be streamlined to only start and end points of all the respective trips for each vehicle id. See code chuck below to tag location naming to geographical tracking data base on a manually complied naming - GPS values csv file.

```{r, trip start and end points}
tmps <- cgps %>% #start point of trip 
        group_by(id,trip) %>%
        summarise (count=n(), timestamp = first(Timestamp), lat = first(rlat), long= first(rlong)) %>%
        filter(count>1) %>% #removing trip with single point
        ungroup()

tmpe <- cgps %>% #end point of trip 
        group_by(id,trip) %>%
        summarise (count=n(),timestamp = last(Timestamp), lat = last(rlat), long= last(rlong)) %>%
        filter(count>1) %>% #removing trip with single point
        ungroup()
        
mgps =  merge(tmps, tmpe, all.x=T, all.y=T)

loc_gps = read_csv("data/aspatial/location_gpsmapping.csv") #
mgps$id <- as.integer(mgps$id)
mgps$trip <- as.integer(mgps$trip)
mgps <- mgps %>% arrange(id, trip, timestamp) %>%
  left_join(loc_gps, by=c("lat", "long"))

write.csv(mgps, "data/aspatial/trip_gps4.csv", row.names  = FALSE)
rm(tmpe,tmps)
```

Manually, one could start to triangulate the matching of credit card with vehicle id by using following visualisation aid: 

1. __Plot via tidygraph, ggirafe or ploty__. Focus on the transaction location and timestamp of respective card holders.

```{r}
g <- fjoin %>% filter(ccard  %in% c("6899")) %>% arrange(ccard, timestamp) %>%
  separate(timestamp, into = c("dat","time"), sep=" ",remove = FALSE) %>%
  ggplot(aes(x = reorder(location, hr), fill=cardtype)) + 
  geom_bar_interactive(aes(tooltip = time), width=0.5) + 
  facet_grid(ccard~day, scale = 'free') +
  scale_fill_manual(values=c("#1569C7", "orange", "green"))+
  scale_y_continuous(breaks=seq(0,2,1)) +
  labs(title = "Transaction Timestamp at Locations for Credit Card No.",
       y="No. of Transaction",
       x="",
       fill="Card Type") + 
  theme_classic()+ 
  theme(axis.text.x = element_text(size=6,angle=90, vjust= 0.9),
        axis.text.y = element_text(size=6),
        axis.title.y = element_text(size=6),
        panel.grid.minor = element_blank(),
        legend.direction="vertical",
        legend.title = element_text(color = "blue", size = 8),
        legend.background = element_rect(fill = "light yellow"),
        legend.text=element_text(size=7),
        legend.key = element_rect(size = 0.5),
        legend.key.size = unit(0.8, 'lines'),
        plot.title = element_text(size=10,hjust = 0.5,face="bold")
        )
gg <- girafe(ggobj=g, width_svg = 6, height_svg=6*0.618)
gg <- girafe_options(gg, opts_tooltip(opacity = .9,
                                    offx = 20, offy = -10, use_fill = TRUE, use_stroke = TRUE,
                                    delay_mouseout = 1000) )
gg
```

2. __timevis__ For timevis, one could merge both transaction and geospatial tracking data sets into one as follow.     

```{r}
# merging GPS with transaction datasets
tmp1 <- fjoin %>%  dplyr::select(ccard,timestamp, location) %>% arrange(timestamp) %>% rename(id=ccard) 
tmp2 <- mgps %>% dplyr::select(id,timestamp, location) %>% arrange(timestamp)
full_ds <- merge(tmp1, tmp2, all.x=T, all.y=T)
glimpse(full_ds)
```

Then prepared the column heading into appropriate data format for timevis. Ensure no duplicate.

```{r}
# filter and grouping code chuck for timevis
visfull_ds <- full_ds %>% filter(id %in% c("6899","5")) %>% 
  mutate(group = id) %>%
  rename(content=location, start=timestamp, cid = id ) %>%
  filter(!is.na(start))

vis_gp <- visfull_ds%>% dplyr::select(group,cid) %>%
 rename(id = group, content = cid) %>% group_by(id,content) %>% summarise(count=n())

glimpse(visfull_ds)
```

Timevis would allow one to view and compared activities in time series. example the plot below allow one to determine activities for credit card 1286 was a good fit to geospatial tracking data of vehicle id 22. One could determine whether transacted location tally with the gps location  based on transacted timeline. However, the data set excluded loyalty card only transaction due to lack of time dimension. Nonetheless, one could use the tracking data to verify indeed whether the card holder present in the location for loyalty card only transaction. Nevertheless, one need to switch between tmap, tidygraph, datatable and timevis to find the most appropriate visualisation for the matching of owner for vehicle id and credit card.

```{r,layout="l-body",fig.height = 6, fig.align='centre'}
# running timevis
timevis(data = visfull_ds, groups=vis_gp)
```

Code chuck and datatable for geospatial tracking tagged with location naming.

```{r, layout="l-body",fig.height = 6, fig.align='centre'}
datatable( mgps %>% 
  dplyr::select(-count, -loctype) %>% arrange(id,trip),
  filter ='top',
  options = list(
            columnDefs = list(list(className = 'dt-center', targets = "_all"))
            ),
  colnames = c("Vehicle ID","Trip ID","Timestamp","Lat", "Long ", "Location")) %>%
  formatStyle(0, target ='row',color = 'Black', backgroundColor = 'light green', lineHeight ='70%')

```
## 5.3  Additional Locations

During the EDA, its discern there were location within the geospatial tracking data not associated with the transaction locations such as office GASTech, residential for respective vehicle id etc. To determine the location for respective vehicle id, one could find the start and end points for each day from the geospatial tracking data and then determined the most likely residential location. Thereafter map the residential naming to the dataset again. For those remaining unidentified, would use tmap for visual aid and assigned an arbitrary naming to the location. See code chuck for determine home location. To support EDA further, the locations was tagged with appropriate 4 types in a new column "loctype". u.e. Office, Transacted location, Unknown = non transaction location, Residential = home, Industry = airports, scrapyard.       

```{r , finding start and end point for each ID}
# cgps = clean gps data 
tmps <- cgps %>%   # find the start point for each day for respective vehicle ID
  mutate(date = get_day(Timestamp)) %>%
  arrange(id, Timestamp) %>% group_by(id,date) %>%
  summarise(timestamp = first(Timestamp), long=first(long), lat =first(lat))

tmpe <- cgps %>%  # find the end  point for each day for respective vehicle ID
  mutate(date = get_day(Timestamp)) %>%
  arrange(id, Timestamp) %>% group_by(id,date) %>%
  summarise(timestamp = last(Timestamp), long=last(long), lat =last(lat))

startend = merge(tmps, tmpe, by=c("id", "date", "timestamp", "long","lat"), all.x=T, all.y=T)

write.csv(startend, "data/aspatial/startend.csv", row.names  = FALSE)
rm(tmpe, tmps)
```

## 5.4 Exploring Relationship

To explore relationship among the employee, tidygraph, ggraph, igraph and visNetwork would be used. Nonetheless, numerous data preparation needed to support the visualisation. Sample of a visIgraph was appended below. 


# 6.0 Exploration Sharing 

## 6.1 Most Popular Location
### 6.1.1 Popular Location
Reference to the chart below, the most popular location was Katerina's Cafe at a count of 254 transactions vs Hippokampos at 211. The main anomaly centered around imperfect transaction information. The merged data set comprised 1081 transactions with both cards details and 720 with either card details only (i.e. 409 with credit and 311 with loyalty card). The 720 was determined as unique transaction since could not be joined based on date, price and location. Due to lack of date time information on loyalty card transactions, it was difficult to determine whether it was different transactions in the same day or same transaction with different values recorded by the loyalty card. Since it was an investigation, respective card transaction should be taken as an independent and valid transaction until proven otherwise. Thus, there might be duplicated transaction count. Nonetheless, a quick assessment on assuming duplication count, Katerina's Cafe would remain to be the most popular location with potential duplicated 28 count. The table below provided information on individual card transactions only where one could verify with the chart.The dataset used has the relationship between credit - loyalty cards mapped out in which it would explain in the later section. 

```{r}
data <- fjoin %>% count(location, cardtype)
fig <- plot_ly(data, x = ~reorder(location,-n,sum), y = ~n, type = 'bar', name = ~cardtype)
#fig <- fig %>% layout(yaxis = list(title = 'No of Transactions'), xaxis = list(title = 'Location'), barmode = 'stack')
fig <- fig %>% layout( title = 'Frequency of Transactions @ Places of Interest',
          xaxis = list(title = "Location",
                       tickfont = list(
                         size = 10,
                         color = 'rgb(107, 107, 107)')),
          yaxis = list(title = 'No. of Transactions',
           titlefont = list(
             size = 12,
             color = 'rgb(107, 107, 107)'),
           tickfont = list(
             size = 10,
             color = 'rgb(107, 107, 107)')),
          legend = list(title = list(text='Card Type'),
                        x = 0.85,
                        y = 0.75,
                        bgcolor = '#F7E7CE',
                        bordercolor = '#C0C0C0'),
          barmode = 'stack')
fig
```

```{r}
datatable( fjoin %>% 
  dplyr::select(timestamp, location, price,last4ccnum, loyaltynum, cardtype),
  #filter(cardtype !="both") %>%
  filter ='top',class = 'cell-border stripe',rownames=FALSE,
  options = list(
            columnDefs = list(list(className = 'dt-center', targets = "_all"))
            ),
  colnames = c("DateTime","Location","Price($)","Credit Card No.", "Loyalty Card No.", "Transacted Card")) %>%
  formatStyle(0, target ='row',color = 'Black', backgroundColor = 'light green', lineHeight ='70%')
```

EDA was done on the data set from the above mentioned table. One interesting observation was that Korons Mart and Daily Deals (i.e. 18 and 1 transactions) were places where transactions were performed with either one card only (See Chart Below) as compared to others. In Korons Mart, there seemed to be a pattern where a card holder after a transaction with only loyalty card would have a next day transaction with credit card only . This was different from most scenarios like in Frydos Autosupply, where the main discerned pattern was that individual cards transacted on similar day or it just sporadic transactions.

```{r, layout="l-body",fig.height = 6, fig.align='centre'}
g <- fjoin %>%
  filter (location=="Kronos Mart") %>% 
  ggplot(aes(x=day, fill=cardtype)) + 
  geom_bar_interactive(aes(tooltip = timestamp, data_id = ccard)) +
  scale_fill_manual(values=c("orange", "#2E8B57"))+
  scale_y_continuous(breaks=seq(0,2,1)) +
  scale_x_continuous(breaks=seq(6,19,1)) + 
  labs(title = expression(underline("Date of Transaction & Count at Kronos Mart with Facet(Credit Card No)")),
       y="No. of Transaction",
       x=" X Jan 2014",
       fill="Card Type") + 
  facet_grid(row = vars(ccard), scales="free_y", space="free_y")+  
  theme_classic()+ 
  theme(axis.text.x = element_text(size=6),
        axis.text.y = element_text(size=6),
        axis.title.x = element_text(size=8),
        axis.title.y = element_text(size=8),
        panel.grid.minor = element_blank(),
        legend.direction="vertical",
        legend.title = element_text(color = "blue", size = 8),
        legend.background = element_rect(fill = "light yellow"),
        legend.text=element_text(size=7),
        legend.key = element_rect(size = 0.5),
        legend.key.size = unit(0.8, 'lines'),
        plot.title = element_text(size=10,hjust = 0.5,face="bold"),
        strip.text.y = element_text(size = 6)
        )

gg <- girafe(ggobj=g, width_svg = 6, height_svg=6*0.618)
gg <- girafe_options(gg, opts_tooltip(opacity = .9,
                                 offx = 20, offy = -10, use_fill = TRUE, use_stroke = TRUE,
                                 delay_mouseout = 1000))
gg
```

```{r}
g <- fjoin %>% separate(timestamp, into = c("dat","time"), sep=" ",remove = FALSE) %>%
  filter(location=="Frydos Autosupply") %>%
  filter(is.na(last4ccnum)|is.na(loyaltynum)) %>%
  ggplot(aes(x=day, fill=cardtype)) + 
  geom_bar_interactive(aes(tooltip = time, data_id = ccard),width=0.9) +
  scale_fill_manual(values=c("orange","#2E8B57"))+
  scale_y_continuous(breaks=seq(0,3,1)) +
  scale_x_continuous(breaks=seq(6,19,1)) + 
  labs(title = expression(underline("Date of Transaction & Count at Frydos Autosupply with Facet(Credit Card No)")),
       y="No. of Transaction",
       x="X Jan 2014",
       fill="Card Type") + 
  facet_grid(row = vars(ccard))+  
  theme_classic()+ 
  theme(axis.text.x = element_text(size=6),
        axis.text.y = element_text(size=6),
        axis.title.x = element_text(size=8),
        axis.title.y = element_text(size=8),
        panel.grid.minor = element_blank(),
        legend.direction="vertical",
        legend.title = element_text(color = "blue", size = 8),
        legend.background = element_rect(fill = "light yellow"),
        legend.text=element_text(size=7),
        legend.key = element_rect(size = 0.5),
        legend.key.size = unit(0.8, 'lines'),
        plot.title = element_text(size=10,hjust = 0.5,face="bold"),
        strip.text.y = element_text(size = 6)
        )
gg <- girafe(ggobj=g, width_svg = 6, height_svg=6*0.618)
gg <- girafe_options(gg, opts_tooltip(opacity = .9,
                                 offx = 20, offy = -10, use_fill = TRUE, use_stroke = TRUE,
                                 delay_mouseout = 1000))
gg
```

### 6.1.2 Popular Time Frame 

We assumed that the credit timestamp information was associated with time of transaction and the card holder left the location within minutes after the transaction. Thus for Katerina's Cafe, the popular time should around -1hr from the time stamp. i.e. busy during lunch (1200 - 1400hrs) and dinner (1700-2000hrs) hours. Based on the date time chart below, its also observed Katerina's cafe do not operate for breakfast timing. For weekend, less customers for lunch hours in particular on Sunday but more tend to stream in earlier for dinner. On weekday, dinner crowd tend to stay longer as compared to weekend. Nonetheless, most customer left prior to 22OOhrs. (The time value for Loyalty card only transaction would be taken as null since its do not have the time stamp)   

```{r} 
p <- fjoin %>% filter (location=="Katerina Cafe")  %>% 
  ggplot(aes(x=day, fill=cardtype)) + 
  geom_bar_interactive(aes(tooltip = ccard, data_id = ccard), width=0.9) + 
  scale_y_continuous(breaks=seq(0,15,5)) +
  scale_x_continuous(breaks=seq(6,19,1)) + 
  labs(title = expression(underline("Transaction Count at Katerina's Cafe with Facet(Hours) from 6-19 Jan 14")),
       y="No. of Transaction",
       x="X Jan 2014",
       fill="Card Type") + 
  scale_fill_manual(values=c("#1569C7", "orange","#2E8B57")) +
  theme_light() +
  facet_grid(row = vars(hr),space="free_y") +
  theme(axis.text.x = element_text(size=4),
        axis.text.y = element_text(size=4),
        axis.title.x = element_text(size=6),
        axis.title.y = element_text(size=6),
        panel.grid.minor = element_blank(),
        legend.direction="vertical",
        legend.title = element_text(color = "blue", size = 6),
        legend.background = element_rect(fill = "light yellow"),
        legend.text=element_text(size=6),
        legend.key = element_rect(size = 0.5),
        legend.key.size = unit(0.8, 'lines'),
        plot.title = element_text(size=8,hjust = 0.5,face="bold"))

girafe(ggobj=p, width_svg = 6, height_svg=6*0.618)
```

When EDA further on the time dimension in day /work day, one could observe that selected locations only have either weekday or weekend transactions. Weekend only transactions were normally associated with recreational like museum, golf course etc. Generally, pace was much slower in the week end as compared to week day especially in the morning.

```{r, location vs day} 
p <- fjoin %>% count(day, location) %>% arrange(desc(n)) %>%
  ggplot(aes(x=day, y=reorder(location,n, sum), fill = n)) +
  geom_tile_interactive(aes(tooltip = n, data_id = location ), colour="white") +
  scale_x_continuous(breaks=seq(6,19,1)) + 
  labs(title = expression(underline("Date of Transaction at Location of Interest. (6-19 Jan 14)")),
       y="Location",
       x="Day(X Jan 2014)",
       fill ="Transaction Count") + 
  #geom_text(aes(label = n), colour = "orange", size = 2) +
  scale_fill_gradient(low="blue", high="red")+
  theme_classic() +
  theme(axis.text.x = element_text(size=5),
        axis.text.y = element_text(size=5),
        axis.title.x = element_text(size=6),
        axis.title.y = element_text(size=6),
        panel.grid.minor = element_blank(),
        legend.direction="vertical",
        legend.title = element_text(color = "blue", size = 4),
        legend.background = element_rect(fill = "light yellow"),
        legend.text=element_text(size=4),
        legend.key = element_rect(size = 0.5),
        legend.key.size = unit(0.8, 'lines'),
        plot.title = element_text(size=8,hjust = 0.5,face="bold"))

girafe(ggobj=p, width_svg = 6, height_svg=6*0.618)
```

For weekday only transaction, its could categorise into 2 groups, namely industrial vs cafe locations. For industrial locations, it seemed that there were a planned routine for GAStech personnel to visit them. In addition, the GAStech personnel visited most of coffee related cafes only during weekday and in particular at the morning session.

```{r, industrial locations} 
p <- fjoin %>% 
  count(day, location) %>% arrange(desc(n)) %>%
  filter( location %in% c("Abila Airport", "Abila Scrapyard","Max Iron & Steel", "Kronos Pipe", "Carlyle Chemical", "Stewart and Sons", "Nationwide Refinery") )%>%
  ggplot(aes(x=day, y=reorder(location,n, sum), fill = n)) +
  geom_tile_interactive(aes(tooltip = n, data_id = location ), colour="white") +
  scale_x_continuous(breaks=seq(6,19,1)) + 
  labs(title = expression(underline("Date of Transaction at Locations associated with GASTech. (6-19 Jan 14)")),
       y="Location",
       x="X Jan 2014",
       fill ="Transaction Count") + 
  #geom_text(aes(label = n), colour = "orange", size = 2) +
  scale_fill_gradient(low="blue", high="red")+
  theme_classic() +
  theme(axis.text.x = element_text(size=5),
        axis.text.y = element_text(size=5),
        axis.title.x = element_text(size=6),
        axis.title.y = element_text(size=6),
        panel.grid.minor = element_blank(),
        legend.direction="vertical",
        legend.title = element_text(color = "blue", size = 4),
        legend.background = element_rect(fill = "light yellow"),
        legend.text=element_text(size=4),
        legend.key = element_rect(size = 0.5),
        legend.key.size = unit(0.8, 'lines'),
        plot.title = element_text(size=8,hjust = 0.5,face="bold"))

#tooltip_css <- "background-color:gray;color:white;font-style:italic;padding:10px;border-radius:1px;"
girafe(ggobj=p, width_svg = 6, height_svg=6*0.618) 

```

When delved into transaction time, there were interesting patterns being detected. Example, Kronos Mart was the only place with transaction at 3am+. Series of cafe like Bean There Done That, Jack Magical Beans etc have only 12pm sharp transactions which assessed to be abnormal.(Could verify with the data table provided above) Going through the tooltips in the time plot, one could also determine the peak hours based on transaction vol for the specific location if any.  

```{r, location vs hr, layout="l-body",fig.height = 6, fig.align='centre'} 
p <- fjoin %>% count(hr, location) %>% arrange(desc(n)) %>%
  ggplot(aes(x=hr, y=reorder(location, n, sum), fill = n)) +
  geom_tile_interactive(aes(tooltip = n, data_id = location ), colour="white") +
  scale_x_continuous(breaks=seq(0,24,2)) + 
  labs(title = expression(underline("Transaction Patterns at Place of Interest within a Day")),
       y="Location",
       x="Time(Hr)",
       fill ="Transaction Count") + 
  #geom_text(aes(label = n), colour = "orange", size = 2) +
  scale_fill_gradient(low="blue", high="red")+
  theme_classic()+
  theme(axis.text.x = element_text(size=5),
        axis.text.y = element_text(size=5),
        axis.title.x = element_text(size=6),
        axis.title.y = element_text(size=6),
        panel.grid.minor = element_blank(),
        legend.direction="vertical",
        legend.title = element_text(color = "blue", size = 4),
        legend.background = element_rect(fill = "light yellow"),
        legend.text=element_text(size=4),
        legend.key = element_rect(size = 0.5),
        legend.key.size = unit(0.8, 'lines'),
        plot.title = element_text(size=8,hjust = 0.5,face="bold"))

#tooltip_css <- "background-color:gray;color:white;font-style:italic;padding:10px;border-radius:1px;"
girafe(ggobj=p, width_svg = 6, height_svg=6*0.618)
```

### 6.1.3 Other Indentified Patterns

It also observed that most card holders have favourite locations that they would patronise very frequently for breakfast, lunch or dinner. For example credit card holders "4434" and "6816",  Brew Served and Guy Gyros. So any deviation from the patterns could potential connote anomalies. 

```{r,layout="l-body",fig.height = 6, fig.align='centre'}
fjoin %>% filter(ccard  %in% c("4434")) %>%
  ggplot(aes(x = location, fill=cardtype)) +
  geom_bar_interactive(aes(tooltip = hr), width=0.5) + 
  facet_grid(ccard~day, scale = 'free_x') +
  scale_fill_manual(values=c("#1569C7", "orange", "green"))+
  scale_y_continuous(breaks=seq(0,2,1)) +
  labs(title = "Date of Transaction & Count at Locations for Facet(Credit Card).",
       y="No. of Transaction",
       x="",
       fill="Card Type") + 
  theme_classic()+ 
  theme(axis.text.x = element_text(size=8,angle=90, vjust= 0.9),
        axis.text.y = element_text(size=6),
        axis.title.y = element_text(size=8),
        panel.grid.minor = element_blank(),
        legend.direction="vertical",
        legend.title = element_text(color = "blue", size = 8),
        legend.background = element_rect(fill = "light yellow"),
        legend.text=element_text(size=7),
        legend.key = element_rect(size = 0.5),
        legend.key.size = unit(0.8, 'lines'),
        plot.title = element_text(size=10,hjust = 0.5,face="bold")
        )
fjoin %>% filter(ccard  %in% c("6816")) %>%
  ggplot(aes(x = location, fill=cardtype)) + 
  geom_bar_interactive(aes(tooltip = hr), width=0.5) + 
  facet_grid(ccard~day, scale = 'free_x') +
  scale_fill_manual(values=c("#1569C7", "orange", "green"))+
  scale_y_continuous(breaks=seq(0,2,1)) +
  labs(title = "Date of Transaction & Count at Locations for Facet(Credit Card).",
       y="No. of Transaction",
       x="",
       fill="Card Type") + 
  theme_classic()+ 
  theme(axis.text.x = element_text(size=8,angle=90, vjust= 0.9),
        axis.text.y = element_text(size=6),
        axis.title.y = element_text(size=8),
        panel.grid.minor = element_blank(),
        legend.direction="vertical",
        legend.title = element_text(color = "blue", size = 8),
        legend.background = element_rect(fill = "light yellow"),
        legend.text=element_text(size=7),
        legend.key = element_rect(size = 0.5),
        legend.key.size = unit(0.8, 'lines'),
        plot.title = element_text(size=10,hjust = 0.5,face="bold")
        )
```

From the plot on the frequency of transaction for credit cards, one could observe that the transaction activities could potential be cluster into 3 groups. First group (start from 3484 to 8411 in the chart below ) with high frequency of transaction activities and gradually reduced as one move down the chart. Second group (start from 3492 to 4530) with medium frequency of transnational activities but steep reduction curve as move down. Last group, namely 5010, 9152 and 9614 has relatively low frequency of transaction activities. This chart might subsequently aid the correlation of transaction data to geospatial tracking information so that one could associate cluster vehicle ID to vehicle ID icate the card holder based on vehicle ID. Lastly, it was to be noted that credit card 9551 has relative lower number of transactions via both cards as compared to the rest. 

```{r}
data <- fjoin %>% count(ccard, cardtype) 
fig <- plot_ly(data, x = ~reorder(ccard,-n,sum), y = ~n, type = 'bar', name = ~cardtype)
#fig <- fig %>% layout(yaxis = list(title = 'No of Transactions'), xaxis = list(title = 'Location'), barmode = 'stack')
fig <- fig %>% layout( title = 'Frequency of Transactions based on Credit Card',
          xaxis = list(title = "Credit Card No.",
                       tickfont = list(
                         size = 10,
                         color = 'rgb(107, 107, 107)')),
          yaxis = list(title = 'No. of Transactions',
           titlefont = list(
             size = 12,
             color = 'rgb(107, 107, 107)'),
           tickfont = list(
             size = 10,
             color = 'rgb(107, 107, 107)')),
          legend = list(title = list(text='Card Type'),
                        x = 0.85,
                        y = 0.75,
                        bgcolor = '#F7E7CE',
                        bordercolor = '#C0C0C0'),
          barmode = 'stack')
fig
```

## 6.2 Inclusion of Vehicle Geospatial Tracking Data

The geospatial would assist to verify whether the card holder/vehicle owner did travel to the transacted location once mapping of credit card to vehicle ID was done with confidence. With that location information, one could possible gain insights on the whether individual card transaction was done by the card holder/vehicle owner. Nonetheless, GPS has it own inadequacy such as GPS errors. Moreover, the geospatial tracking provide additional insights on possible location that individual has traveled which was beyond the transacted locations.  

Reference to location setting stipulated in section 5.3, a bar chart stipulated on location type was shown below. Code chuck was relatively similar to the above less some changes in the parameters, thus it would not be displayed here. From the chart, "NA" referred to inconsistent location due to GPS error. This largely happened to Vehicle ID 28 and less on 9. Truck 105 and 101 might violate company policy where trucks were not mean for personnel usage if visited to locations beyond the industrial sites were exclusive. Interesting, vehicle ID 15,24,13 and 21 less of ID 35,25,34,23 traveled beyond those identified transactions locations.  

```{r, echo=FALSE }
data <- mgps %>% count(id, loctype)%>%mutate(loctype=ifelse(is.na(loctype),"NA",loctype))
fig <- plot_ly(data, x = ~reorder(id,-n,sum), y = ~n, type = 'bar', name = ~loctype, color = ~loctype,
               colors=c("steel blue","grey 50","orange","sky blue","yellow green", "red")
               )
fig <- fig %>% layout( title = 'Numnber of Travelled Locations based on Vehcile ID',
          xaxis = list(title = "Vehicle ID",
                       tickfont = list(
                         size = 10)),
          yaxis = list(title = 'No. of Locations',
           titlefont = list(
             size = 12),
           tickfont = list(
             size = 10)),
          legend = list(title = list(text='Location Type'),
                        x = 0.95,
                        y = 0.75,
                        bgcolor = '#F7E7CE',
                        bordercolor = '#C0C0C0'),
          barmode = 'stack')
fig
```

