---
title: "Assignment - VAST Challenge 2021"
description: |
  [VAST Challenge 2021](https://vast-challenge.github.io/2021/). Applying visual analytics to gain Insight.....  
author:
  - name: Choo T Tan
    url: {}
date: 06-28-2021
output:
  distill::distill_article:
    toc: true
    toc_depth: 2
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, error = FALSE, fig.retina = 3)
```
```{r echo = FALSE, warning = FALSE}
packages <- c('sf','tidyverse', 'igraph', 'plotly', 'ggiraph','lubridate', 'clock', "ggraph", 'DT', 'tmap','raster', 'scales')
for (p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p,character.only = T)
}
```

# 1.0 Introduction 
The assignment is based on [VAST Challenge 2021](https://vast-challenge.github.io/2021/) where it has selected solve the [Mini Challenges 2 (MC2)](https://vast-challenge.github.io/2021/MC2.html) out of the 3 mini challenges via visual analytics out. The fictitious scenario was based on a Tethys-based natural gas production company GAStech in the country of Kronos where it has made remarkable profits and strong relationship with the government. However, GAStech has not been as successful in demonstrating environmental stewardship. Several employee went missing in January 2014 after a successful initial public offering. It was suspected that the disappearance might be associated with an organization known as the Protectors of Kronos (POK). However, things may not be so simplicity. Thus, one has been tasked to assist the law enforcement from Kronos and Tethys in solving the assigned task via visual analytics. 

# 2.0 Requirements 
The main task was to identify suspicious patterns of behavior from the transaction done by GASTech employees. You must cope with uncertainties that result from missing, conflicting, and imperfect data to make recommendations for further investigation.there are 4 main CSV files with Korons geospatial data [here] and it based on last 14 days, 6 - 19 January 2014 prior to the disappearance. The CSV files are namely (1) credit card transaction, (2) loyalty card transaction, (3) geospatial tracking data for company cars which not know to employee, (4) car assignment. The relevant questions to be answered were: 

1. Using just the credit and loyalty card data, identify the most popular locations, and when they are popular. What anomalies do you see? What corrections would you recommend to correct these anomalies? Please limit your answer to 8 images and 300 words.

2. Add the vehicle data to your analysis of the credit and loyalty card data. How does your assessment of the anomalies in question 1 change based on this new data? What discrepancies between vehicle, credit, and loyalty card data do you find? Please limit your answer to 8 images and 500 words.

3. Can you infer the owners of each credit card and loyalty card? What is your evidence? Where are there uncertainties in your method? Where are there uncertainties in the data? Please limit your answer to 8 images and 500 words.

4. Given the data sources provided, identify potential informal or unofficial relationships among GASTech personnel. Provide evidence for these relationships. Please limit your response to 8 images and 500 words.

5. Do you see evidence of suspicious activity? Identify 1- 10 locations where you believe the suspicious activity is occurring, and why Please limit your response to 10 images and 500 words.

The constraints imposed was that only R tools could be used to complete the assignment. 

# 3.0 Approach and Overview

The investigation will be done in 3 main steps:

1. **Preliminary Analysis**. To prepare the data for subsequent analysis, intention was to apply the right data type to the data set. Thereafter to link credit with loyalty card and discovered the disparity in the data set. Explain the necessary preparation of the geospatial tracking data that would aid the exploratory. Subsequently to determine the GPS values for the interest location to establish the link between credit card to geospatial tracking data. GPS values would be determined via investigative work. 

2. **Exploratory Data Analysis (EDA)**.  Explain the various library that ouTo identify patterns and anomalies from the transactions and geospatial tracking. Subsequent, to correlate the discovered insights in suitable narrative for further investigation. 

# 4.0 Preliminary Analysis

Samples of credit and loyalty dataset were shown below. Observed that there were more credit than loyalty card transactions. Whether it was a scenario on independent credit card transaction without loyalty card or vice verse was something to be discovered later. Moreover credit card has transaction data time information while loyalty card only has transaction date only. Reference to the respective column datatype, need to covert "timestamp" to datetime/date,"last4ccnum" and loyaltynum" to character as technically, it was not a numeric data type. When one explored the "timestamp" data deeper, its observed that the variable has different date format after 13 Jan. i.e. 2014(%Y) vs 14(%y). Would need to be clean. 

Glimpse of credit card dataset:

```{r}
credit <- read_csv("data/aspatial/cc_data.csv")
glimpse(credit)
```
Glimpse of loyalty card dataset:

```{r}
loyalty <- read_csv("data/aspatial/loyalty_data.csv")
glimpse(loyalty)
```

```{r, echo=FALSE, results = FALSE}
uniC<- length(unique(credit$last4ccnum))
uniL <- length(unique(loyalty$loyaltynum))
uniCL <- length(unique(credit$location))
uniLL <- length(unique(loyalty$location))
dCLL <- credit$location[!(credit$location %in% loyalty$location)]
dCLP <- credit$price[!(credit$location %in% loyalty$location)]
```

Reference to the company employee records in challenge 1, GASTech has 54 staffs. However when do a unique count on the credit and loyalty card numbers, it was `r uniC` and `r uniL` count respectively. Its alluded that one of the staff could have 2 credit cards. Moreover,a unique count on the number of transacted locations for each dataset has shown that there were `r uniCL` and `r uniLL` locations for credit and loyalty card respectively. The additional location in credit card dataset was known as "`r dCLL`" with a transaction amount "`r dCLP`". From the transaction price captured respectively in both dataset, interesting to note that the mean was relatively close but min-max and inter-quartile range were quite different. This could be attributed by those single card transactions. 

```{r}
print("Credit Card Transaction Statistics.")
summary(credit$price)

print("Loyalty Card Transaction Statistics.")
summary(loyalty$price)
```
On the geospatial tracking dateset, similar observation on timestamp and id data type. Given there were 35 and 5 unique private company car and truck respectively as compared to 54 GAStech personnel, not all individual could be associated with geospatial tracking data.

Glimpse of geospatial tracking dataset:

```{r}
gps <- read_csv("data/aspatial/gps.csv")
glimpse(gps)
```

# 5.0 Data Wrangling

The intention is to prepare and establish the foundation layer to effectively link numerous datasets for subsequent exploration. The first step was to establish the link between credit and loyalty card transactions based on timestamp, location, and price. Thereafter, to establish geospatial values for the location which will act as a link-pin to geospatial tracking dataset. Also, the need to segregate the geospatial dataset into respective trips within the day for respective veh id.            

## 5.1 Preparation of Personnel Node
This will be built based on MC1 employee records. Only relevant information will be used. 

Glimpse of personnel information:

```{r, warning = FALSE}
#Loading the base file 
GAStech_persnode<- read_csv("data/aspatial/employeeinfo.csv")
glimpse(GAStech_persnode)
```

## 5.1 Mapping Credit to Loyalty Card

Perform required data wrangling based on observation in Section 4. To resolve the datetime format for timestamp (i.e. using lubridate library) and set all card number as character. In addition, create date (i.e. Calendar Date, rename timestamp in loyalty card to date), weekday and hour for associated data set with the relevant information. 

Glimpse of prepared credit card dataset:

```{r clean up credit up, echo = FALSE}
credit$last4ccnum = as.character(credit$last4ccnum) # convert it factor

#cleaning up on datetime format, since there is %y vs %Y. Try to use ifelse but syntac error that cant resolve
credit <- credit %>% # separate them into fine entity
  separate(timestamp, into = c("date","time"), sep=" ",remove = TRUE) %>%
  separate(time, into = c("hr", "min"), sep=":",remove = TRUE) %>%
  separate(date, into = c("mth", "day", "yr"), sep="/",remove = TRUE) %>%
  mutate(yr=2014)

pack <- c('yr','mth','day','hr','min') # convert to numeric since make_datetime need numeric format
for (p in pack){
  credit <- credit %>% mutate_at(c(p),as.numeric)
}

credit  <- credit %>% 
  mutate(timestamp = make_datetime(yr,mth,day,hr,min)) %>%
  mutate(date = make_date(yr,mth,day)) %>%
  dplyr::select(-yr,-mth,-min) %>%
  relocate(timestamp, date, .before=day) %>%
  arrange(last4ccnum, timestamp)

credit$wkday <- lubridate::wday(credit$timestamp, label= TRUE, abbr = FALSE)

glimpse(credit)
```
```{r echo = FALSE, eval = FALSE}
#cant get it work
#credit <- credit %>% # separate them into fine entity
#  separate(timestamp, into = c("date","time"), sep=" ",remove = FALSE)%>%
#  arrange(last4ccnum,timestamp)
#credit$timestamp <- date_time_parse(credit$timestamp,  zone ="", format = "%m/%d/%Y %H:%M") # cover to dttm
#year(credit$timestamp)=2014 # due to %y vs %Y
#credit$date = dmy(credit$date)
#credit$weekday = lubridate::wday(credit$date, label=TRUE, abbr=FALSE)
#glimpse(credit)
```

Glimpse of prepared loyalty card dataset:

```{r clean up loyalty card, echo = FALSE}
loyalty$loyaltynum = as.character(loyalty$loyaltynum)
loyalty<-loyalty %>% 
  separate(timestamp, into = c("mth", "day", "yr"), sep="/",remove = TRUE) %>%
  mutate(yr=2014)

pack <- c('yr','mth','day') # convert to numeric since make_datetime need numeric format
for (p in pack){
  loyalty  <- loyalty %>% mutate_at(c(p),as.numeric)
}

loyalty  <- loyalty %>% 
  mutate(date = make_date(yr,mth,day)) %>%
  dplyr::select(-yr,-mth) %>%
  arrange(loyaltynum)

glimpse(loyalty)
```

__Inner join for both Data Sets__. Inner join based on date, location and price for inner join. Thereafter, compute the number of distinct count between a credit-loyalty tagged. Logically, there should only be one distinct pair. However, for more than one distinct pair, implied the credit card owner could be using numerous loyalty cards or vice verse.  It observed that inner join has 1087 observations, while anti join has 409 and 311 disjoint for credit and loyalty card transaction respectively. Technically, inner join should generated only 1081 observations and the difference would be accounted later. The anti join set implied there were transactions with only one of the card, possible due to shop limitations or individual behaviour. When determined the unique count for both cards and location, it was observed that the unique count for credit and loyalty card remained the same as previous count for inner and anti join (loyalty) less the anti join (credit). For credit, it short of 2 credit card number namely 5010 and 4530. For this card holders, loyalty card would be used whenever there was a credit card transaction. With all cards number accounted in the inner join set, all possible relationship between both cards should be captured within. On location, the inner join has 2 locations less than the credit card transaction, namely, Korons Mart and Daily Dealz. This implied that at any onetime, only one card has been used in those places. 

```{r, inner join Credit and Loyalty to determine relationship, echo=TRUE}
ijoin <- credit %>%
  inner_join(loyalty,by=c('date','location','price','day')) %>%
  group_by(last4ccnum) %>%
  mutate(ndist = n_distinct(loyaltynum)) %>%
  ungroup() %>%
  group_by(loyaltynum) %>%
  mutate(ndist = if_else(ndist==1,n_distinct(last4ccnum), ndist)) %>%
  relocate(wkday, .before=location) %>%
  ungroup()

tmp1 <- credit %>%
  anti_join(loyalty,by=c('date','location','price','day'))

tmp2 <- loyalty %>%
  anti_join(credit,by=c('date','location','price','day'))

ijoin
```
```{r, results=FALSE}
length(unique(ijoin$last4ccnum))
length(unique(ijoin$loyaltynum))
length(unique(ijoin$location))
credit$location[!(credit$location %in% ijoin$location)]
```

__Bipartite Graph for Credit-Loyalty Pair__. Will use igraph to built a bipartite graph with nodes as credit and loyalty cards and transaction as edges. Edge weight was based on number of transactions based on a unique credit-loyalty tagging. To minimise cluttering in discovering the outlier tagging (i.e. more than one to one tagging), we have filtered the dataset for distinct pairing count >=2 after group by via cards. With the necessary colour inking done on the nodes and edge, the bipartite graph was shown below.

```{r message = FALSE, warning = FALSE}
#forming the bipartite graph
bigraph <- ijoin %>% # filter out unique pairing and count
  filter(ndist >= 2)%>%
  group_by(last4ccnum,loyaltynum) %>%
  summarise(weights=n()) %>%
  mutate_at(c("weights"), as.numeric)%>%
  arrange(loyaltynum) %>%
  ungroup()

#plot bipartite graph
bg<- graph.data.frame(bigraph, directed = FALSE)
V(bg)$type <- bipartite_mapping(bg)$type # assign vertex or nodes
shape <- c("circle", "square")
E(bg)$color[E(bg)$weights<=5] <- 'red'
E(bg)$color[E(bg)$weights>5] <- 'sky blue'
```

```{r, Other method to plot. eval = FALSE}
set.seed(2017)
ijoin %>% 
  filter(ndist>=2) %>%
  group_by(last4ccnum,loyaltynum) %>%
  summarise(weights=n()) %>%
  graph_from_data_frame() %>%
  ggraph(layout = 'linear', circular = TRUE)  + #layout ="fr") +
  geom_edge_link(aes(alpha=weights, width = weights) ) + 
  geom_node_point(size=6, colour = "lightblue") + 
  geom_node_text(aes(label = name), color = "red", repel = TRUE) +
  theme_void()
```

```{r message = FALSE,layout="l-body",fig.height = 6, fig.align ="centre", fig.cap = "Bipartite Graph of Credit(Orange) and Loyalty(Pink) Cards.", warning = FALSE}
plot(bg, layout=layout.bipartite, 
     vertex.color=c("orange","pink")[V(bg)$type+1], vertex.size=20, vertex.label.cex=0.8,
     vertex.shape = shape[V(bg)$type+1],
     edge.width = E(bg)$weights*0.8,
     edge.label=E(bg)$weights, edge.label.cex=0.8, edge.label.color ="black", legend=TRUE)
```

From the bipartite graph, L6267 was used by both credit cards 6691 and 6899. That accounted for the extra credit card when compared to the number of loyalty card as in Section 4. There should be some form of relationship between credit card 1286 and 9241 given the high usage of 9241 loyalty card by 1286 credit card holder. Nonetheless, 1283 will be tagged to L3572. For weight equal 1, its discerned a one time usage of someone loyalty card. When explore further via group by of relevant parameters, it was discerned that both card holders happened to transact on the same day at the same location for the same price, duplication was created due to nature of inner join. Moving on credit card would be used as the anchoring point for exploration where tagged of loyalty to credit card would be based on the linkage established here. 

```{r}
head(ijoin %>% group_by(date,day,location,price, last4ccnum)%>% summarise(count=n()) %>% arrange(desc(count)))
```
```{r, warning= FALSE}
# load the mapping of relationship generate the relationship link
mapping <- read_csv("data/aspatial/mapping.csv")
mapping$tmpC <- as.character(mapping$tmpC)
mapping$tmpL <- as.character(mapping$tmpL)
```
```{r,final credit-loyalty dataset }
ijoin <- ijoin %>%
  filter(!(last4ccnum == "4795" & loyaltynum == "L2070")) %>%
  filter(!(last4ccnum == "8332" & loyaltynum == "L8566")) %>%
  filter(!(last4ccnum == "5368" & loyaltynum == "L6119")) %>%
  filter(!(last4ccnum == "7889" & loyaltynum == "L2247")) %>%
  filter(!(last4ccnum == "5921" & loyaltynum == "L9406")) %>%
  filter(!(last4ccnum == "4948" & loyaltynum == "L3295")) %>%
  dplyr::select(-ndist)

tmp = merge(tmp1, tmp2, all.x=T, all.y=T )
tmp = merge(ijoin, tmp, all.x=T, all.y=T )

fjoin <- tmp %>% 
          arrange(last4ccnum, loyaltynum) %>%
          left_join(mapping,by= c("loyaltynum"="tmpL")) %>%
          mutate(ccard = ifelse(is.na(last4ccnum),tmpC, last4ccnum)) %>%
          dplyr::select(-tmpC)

fjoin$wkday <- lubridate::wday(fjoin$date, label= TRUE, abbr = FALSE)

write.csv(fjoin, "data/aspatial/cc_loy.csv", row.names  = FALSE)
```

## 5.2 Prepartion of Geospatial Tracking Data 

As per the rest, necessary conversion of Timestamp and id parameters to the proper dataset. To ease the mapping of location to geospatial values, decided to round off its value to three decimal places. The immediate task was to determine the trip within the geospatial tracking dataset. Trip was defined as a continues traveling from point A to B with time lag less than 300secs. 300 secs was arbitrary decided based on screening through the dataset. With the trip formed, one could determine the travelling locations for respective veh ID overtime.  

```{r, prepare gps, eval=FALSE}
# address format 
gps$Timestamp <- date_time_parse(gps$Timestamp,zone ="", format = "%m/%d/%Y %H:%M:%S")
gps$id <- as.character(gps$id)

#compute time difference & rd off GPS 
gps <- gps %>% 
  arrange(id, Timestamp) %>%
  mutate(diff = (Timestamp - lag(Timestamp, default = first(Timestamp)))) %>%
  mutate(rlat = round(lat, digits = 4), rlong = round(long, digits=4))
```

```{r, compute trip, eval=FALSE}
pack <- c( "1", "2","3","4","5","6","7","8","9","10", "11","12","13","14","15","16","17","18","19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "101", "104", "105", "106","107")
# interval <= 5mins considered as a single trip
trip_lag = 300

for (p in pack){
  print(p)
  temp <- gps %>% filter(id==p) %>%
    arrange(id, Timestamp) 
  count = 1
  
  for(i in 1:nrow(temp)){
    if(temp[i,'diff']<=trip_lag){
      temp[i,'trip']=count
    }else{
      count = count + 1
      temp[i,'trip'] = count
     }
  } 
  if(p==1){mgps <- temp
  }else{
    mgps = merge(mgps, temp, all.x=T, all.y=T)  
  }
}
mgps <-  mgps %>% arrange(id, Timestamp)
write.csv(mgps, "data/aspatial/fulltrip_gps.csv", row.names  = FALSE)
```

```{r}
mgps <- read_csv("data/aspatial/fulltrip_gps.csv")
mgps$id = as.factor(mgps$id)
mgps$trip = as.factor(mgps$trip)
```
```{r}
bgmap<- raster::raster("data/geospatial/MC2-tourist_modified.tif")
```

```{r, layout="l-body",fig.height = 6, fig.align='centre', fig.cap = "Example of a trip for Veh ID = 3" }

gps_sf <- st_as_sf(mgps, coords = c("long","lat"), crs = 4326) # should form geometric data first

gps_path <- gps_sf %>% 
  group_by(id, trip) %>%
  summarize(m = mean(Timestamp), do_union=FALSE) %>%
  st_cast("MULTILINESTRING")


gps_path_selected <- gps_path %>%
  filter(id==3, trip==6)
tmap_mode("plot")
tm_shape(bgmap) +
  tm_rgb(bgmap, r = 1,g = 2,b = 3,
       alpha = NA,
       saturation = 1,
       interpolate = TRUE,
       max.value = 255) +
  tm_shape(gps_path_selected) +
  tm_lines()

```
## 5.3 Finding GPS Location for Place of Interest

First, we would find the gaps location for the respective veh ID owner through finding the daily start and end points. 


```{r , finding start and end point for each ID}
tmp1 <- mgps %>% 
  mutate(date = get_day(Timestamp)) %>%
  arrange(id, Timestamp) %>% group_by(id,date) %>%
  summarise(Timestamp = first(Timestamp), long=first(long), lat =first(lat))

tmp2 <- mgps %>%
  mutate(date = get_day(Timestamp)) %>%
  arrange(id, Timestamp) %>% group_by(id,date) %>%
  summarise(Timestamp = last(Timestamp), long=last(long), lat =last(lat))

startend = merge(tmp1, tmp2, by=c("id", "date", "Timestamp", "long","lat"), all.x=T, all.y=T)

write.csv(startend, "data/aspatial/startend.csv", row.names  = FALSE)
```
```{r}
gps_sf <- st_as_sf(startend, coords = c("long","lat"), crs = 4326) # should form geometric data first

gps_path_mline <- gps_sf %>% 
  group_by(id) %>%
  summarize(m = mean(Timestamp), do_union=FALSE) %>%
  st_cast("MULTILINESTRING")

gps_path_point <- gps_sf %>% 
  group_by(id) %>%
  summarize(m = mean(Timestamp), do_union=FALSE) %>%
  st_cast("POINT")

gps_path_point_s <- gps_sf %>% 
   filter(id==5)

gps_path_mline_s<- gps_path %>%
  filter(id==9)

tmap_mode("plot")
tm_shape(bgmap) +
  tm_rgb(bgmap, r =1,g = 2,b =3,
         alpha = NA,
         saturation = 1,
         interpolate = TRUE,
         max.value = 255) +
  tm_shape(gps_path_point) + 
  tm_facets(by="id",free.coords = FALSE) +
  tm_dots("red", size = .5)
  #tm_lines("blue", side = 0.1) +
  #tm_layout(panel.label.rot = c(0, 90), panel.label.size = 2)

```

```{r, startend of trip based on round 4}
mgps4 <- mgps %>%
  mutate(rlat = round(lat, digits = 4), rlong = round(long, digits=4)) 
tmp1 <- mgps4 %>%
        group_by(id,trip) %>%
        summarise (Timestamp = first(Timestamp), lat = first(rlat), long= first(rlong), diff= first(diff))

tmp2 <- mgps4 %>%
        group_by(id,trip) %>%
        summarise (Timestamp = last(Timestamp), lat = last(rlat), long= last(rlong), diff= last(diff))

tgps =  merge(tmp1, tmp2, all.x=T, all.y=T)

loc_gps = read_csv("data/aspatial/loc4.csv") #
tgps4 <- tgps %>% arrange(id, trip, Timestamp) %>%
  left_join(loc_gps, by=c("lat", "long"))

write.csv(tgps4, "data/aspatial/trip_gps4.csv", row.names  = FALSE)
```

```{r}
ggplot(data=fjoin,  aes(x = location, y = price )) + geom_boxplot(fill="pink") + #geom_dotplot(binwidth=2, dotsize=0.25,show.legend = FALSE) + 
 ggtitle("SPopularity on Place of Interest.") + theme_minimal()+ theme(axis.text.x = element_text(size=8, angle=70, vjust= 0.6, hjust = 0.5))
```

```{r}
fjoin %>% filter(!is.na(last4ccnum)|!is.na(loyaltynum)) %>%
ggplot(aes(x = location, y = price )) + geom_boxplot(fill="pink") + #geom_dotplot(binwidth=2, dotsize=0.25,show.legend = FALSE) + 
 ggtitle("SPopularity on Place of Interest.") + theme_minimal()+ theme(axis.text.x = element_text(size=8, angle=90, vjust= 0.6, hjust = 0.5))
```
```{r}
t <- fjoin %>% mutate( "Null" = ifelse(is.na(last4ccnum)|is.na(loyaltynum),1,0))
t %>%
ggplot(aes(x = location, y = price )) + geom_boxplot(fill="pink") + #geom_dotplot(binwidth=2, dotsize=0.25,show.legend = FALSE) + 
 ggtitle("SPopularity on Place of Interest.") + theme_minimal()+ theme(axis.text.x = element_text(size=8, angle=70, vjust= 0.6, hjust = 0.5)) + facet_grid(~Null)
```

```{r}
fjoin %>% filter(!(is.na(last4ccnum))) %>% filter(!(is.na(loyaltynum))) %>%
ggplot(aes(x = location, y = price )) + geom_boxplot(fill="pink") + #geom_dotplot(binwidth=2, dotsize=0.25,show.legend = FALSE) + 
 ggtitle("SPopularity on Place of Interest.") + theme_minimal()+ theme(axis.text.x = element_text(size=8, angle=70, vjust= 0.6, hjust = 0.5))
```

```{r}
p <- ggplot(data=fjoin,  aes(x = location)) + geom_bar_interactive(aes(tooltip=ccard, data_id = ccard), stackgroups = TRUE)  + 
 ggtitle("Popularity on Place of Interest.") +theme_minimal()+  theme(axis.text.x = element_text(size=6, angle=90, vjust= 0.8))

girafe(ggobj=p, width_svg = 6, height_svg=6*0.618)
```


```{r}
fjoin %>% filter(ccard == 1286) %>%
ggplot(aes(x = location)) + geom_bar(show.legend = FALSE, width=.5) + #geom_dotplot(binwidth=2, dotsize=0.25,show.legend = FALSE) + 
 ggtitle("Popularity on Place of Interest.") +theme(axis.text.x = element_text(size=8, angle=90, vjust= 0.9)) + facet_grid(~day, scale = 'free_x')
```
```{r}
fjoin %>% filter(location == "Abila Zacharo") %>% mutate(factor(day))
```

```{r}

fjoin %>% filter(location == "Abila Zacharo") %>% mutate(factor(day)) %>%
  ggplot(aes(x=day)) + geom_bar(show.legend = FALSE) + #geom_dotplot(binwidth=2, dotsize=0.25,show.legend = FALSE) + 
 ggtitle("Popularity on Place of Interest.") +theme(axis.text.x = element_text(size=8, angle=90, vjust= 0.9)) + facet_grid(rows = vars(ccard))

```

```{r}
t <- fjoin %>% mutate(n=1)
```


```{r}
ggplot(data=fjoin, aes(x=hr, y=location, fill=day)) + geom_point(colour="blue")+ scale_fill_gradient(low="red", high="green") + facet_grid(~wkday)
```


```{r}
fjoin %>% count(location, loyaltynum) %>%
  ggplot(aes(x= reorder(location, -n, sum),y= n, fill = loyaltynum) )+ geom_col(stat = "identity") + 
 ggtitle("Popularity on Place of Interest.") + theme_minimal()+ theme(axis.text.x = element_text(size=8, angle=90))
```

```{r}
fjoin %>% filter(!is.na(last4ccnum)) %>% count(location, last4ccnum) %>%
  ggplot(aes(x= reorder(location, -n, sum),y= n, fill = last4ccnum) )+ geom_col(stat = "identity") + 
 ggtitle("Popularity on Place of Interest.") + theme_minimal()+ theme(axis.text.x = element_text(size=8, angle=90))
```
```{r}
fjoin %>% count(location, last4ccnum)fjoin %>% count(location, last4ccnum) %>% filter(!is.na(last4ccnum))
```
